{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e25e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ktr62\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087e6595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are seeking a Machine Learning Engineer with experience in Python, TensorFlow, and natural language processing. The candidate should have knowledge of resume parsing, scoring systems, and data preprocessing. Strong communication and collaboration skills are a plus.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the job description from the text file\n",
    "with open(\"Job_Description.txt\", \"r\", encoding='utf-8') as f:\n",
    "    job_description = f.read()\n",
    "\n",
    "# Optional: Preview the first 300 characters\n",
    "print(job_description[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "790965f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted text from 2 resumes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Folder containing the resumes\n",
    "resume_folder = \"Sample_Resumes\"\n",
    "\n",
    "# List to store extracted resume texts and filenames\n",
    "resumes = []\n",
    "resume_names = []\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    import fitz  # PyMuPDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Loop through all PDF files in the folder and extract text\n",
    "for filename in os.listdir(resume_folder):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(resume_folder, filename)\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        resumes.append(text)\n",
    "        resume_names.append(filename)\n",
    "\n",
    "print(f\"✅ Extracted text from {len(resumes)} resumes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d53ae37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- resume1.pdf ---\n",
      "Resume\n",
      "Name: Alice Johnson\n",
      "Role: Machine Learning Engineer\n",
      "Skills: Python, TensorFlow, Scikit-learn, SQL\n",
      "Experience:\n",
      "Worked on end-to-end ML pipelines. Built classification models for customer churn. Optimized\n",
      "training time using GPU acceleration.\n",
      "Page 1\n",
      "...\n",
      "\n",
      "\n",
      "--- resume2.pdf ---\n",
      "Resume\n",
      "Name: Bob Smith\n",
      "Role: Data Scientist\n",
      "Skills: Pandas, NumPy, Matplotlib, NLP, PyTorch\n",
      "Experience:\n",
      "Developed sentiment analysis tools. Created dashboards with data visualizations. Collaborated with\n",
      "engineering team for deployment.\n",
      "Page 1\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, text in zip(resume_names, resumes):\n",
    "    print(f\"\\n--- {name} ---\\n{text[:500]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ffc3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ktr62\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ktr62\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ranking Complete! Here are the scores:\n",
      "        Resume     Score\n",
      "0  resume1.pdf  0.687633\n",
      "1  resume2.pdf  0.560680\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "# Load a pre-trained model (you can try other models like 'paraphrase-MiniLM-L6-v2')\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load job description\n",
    "with open(\"Job_Description.txt\", \"r\", encoding='utf-8') as f:\n",
    "    job_description = f.read()\n",
    "\n",
    "# Convert job description to embedding\n",
    "job_embedding = model.encode(job_description, convert_to_tensor=True)\n",
    "\n",
    "# Convert each resume to embedding and calculate similarity\n",
    "scores = []\n",
    "for resume_text in resumes:\n",
    "    resume_embedding = model.encode(resume_text, convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(job_embedding, resume_embedding).item()\n",
    "    scores.append(similarity)\n",
    "\n",
    "# Create a DataFrame of results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Resume\": resume_names,\n",
    "    \"Score\": scores\n",
    "})\n",
    "\n",
    "# Sort by score (higher = more relevant)\n",
    "results_df.sort_values(by=\"Score\", ascending=False, inplace=True)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"Score_Output.csv\", index=False)\n",
    "\n",
    "# Display\n",
    "print(\"✅ Ranking Complete! Here are the scores:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
